{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.linalg import svds\n",
    "import dask.dataframe as dd\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>review_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   review_rating  \n",
       "0            3.0  \n",
       "1            5.0  \n",
       "2            3.0  \n",
       "3            5.0  \n",
       "4            4.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv('data/review_data.csv',low_memory=False)\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:(5592224, 4)\n",
      "Test data size:(1398056, 4)\n"
     ]
    }
   ],
   "source": [
    "#Split train and test data for colaborative filtering\n",
    "train_df, test_df = train_test_split(review_df,test_size=0.2,random_state=42)\n",
    "print(f\"Train data size:{train_df.shape}\")\n",
    "print(f\"Test data size:{test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\serji\\anaconda3\\envs\\tf2.17\\Lib\\site-packages\\dask_expr\\_collection.py:4225: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('user_id', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n",
      "c:\\Users\\serji\\anaconda3\\envs\\tf2.17\\Lib\\site-packages\\dask_expr\\_collection.py:4225: UserWarning: \n",
      "You did not provide metadata, so Dask is running your function on a small dataset to guess output types. It is possible that Dask will guess incorrectly.\n",
      "To provide an explicit output types or to silence this message, please provide the `meta=` keyword, as described in the map or apply function that you are using.\n",
      "  Before: .apply(func)\n",
      "  After:  .apply(func, meta=('business_id', 'float64'))\n",
      "\n",
      "  warnings.warn(meta_warning(meta))\n"
     ]
    }
   ],
   "source": [
    "# Convert to Dask DataFrame\n",
    "train_ddf = dd.from_pandas(train_df, npartitions=10)\n",
    "\n",
    "# Map user_id and business_id to indices\n",
    "user_mapping = {user: idx for idx, user in enumerate(train_ddf['user_id'].unique())}\n",
    "business_mapping = {business: idx for idx, business in enumerate(train_ddf['business_id'].unique())}\n",
    "\n",
    "train_ddf['user_idx'] = train_ddf['user_id'].map(user_mapping)\n",
    "train_ddf['business_idx'] = train_ddf['business_id'].map(business_mapping)\n",
    "\n",
    "# Create a sparse matrix\n",
    "train_sparse_matrix = coo_matrix(\n",
    "    (train_ddf['review_rating'], (train_ddf['user_idx'], train_ddf['business_idx'])),\n",
    "    shape=(len(user_mapping), len(business_mapping))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U matrix shape:(1746593, 100)\n",
      "sigma matrix shape:(100, 100)\n",
      "Vt matrix shape:(100, 150344)\n"
     ]
    }
   ],
   "source": [
    "# Perform SVD on the sparse matrix\n",
    "U, sigma, Vt = svds(train_sparse_matrix, k=100)  # k is the number of latent features\n",
    "\n",
    "# Convert sigma to a diagonal matrix\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "print(f\"U matrix shape:{U.shape}\")\n",
    "print(f\"sigma matrix shape:{sigma.shape}\")\n",
    "print(f\"Vt matrix shape:{Vt.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mapping the users and business for the test set\n",
    "test_df['user_idx'] = test_df['user_id'].map(user_mapping).fillna(-1).astype(int)\n",
    "test_df['business_idx'] = test_df['business_id'].map(business_mapping).fillna(-1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.02702614e-02 -7.50603855e-08  2.02125104e-05 ...  8.30224959e-02\n",
      "  4.94407700e-04  8.68592168e-02]\n"
     ]
    }
   ],
   "source": [
    "def batch_predict(test, U, sigma, Vt, batch_size=1000):\n",
    "    predictions = []\n",
    "    for i in range(0, len(test), batch_size):\n",
    "        batch = test.iloc[i:i + batch_size]\n",
    "        batch_ratings = []\n",
    "        for _, row in batch.iterrows():\n",
    "            user_idx = row['user_idx']\n",
    "            business_idx = row['business_idx']\n",
    "            # Predict rating\n",
    "            predicted_rating = np.dot(np.dot(U[user_idx], sigma), Vt[:, business_idx])\n",
    "            batch_ratings.append(predicted_rating)\n",
    "        predictions.extend(batch_ratings)\n",
    "    return np.array(predictions)\n",
    "\n",
    "# Perform batch predictions on the test set\n",
    "test_predictions = batch_predict(test_df, U, sigma, Vt)\n",
    "\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(true_ratings, predicted_ratings, k):\n",
    "    \"\"\"\n",
    "    Calculates Precision@K.\n",
    "\n",
    "    Parameters:\n",
    "    - true_ratings: List of true ratings.\n",
    "    - predicted_ratings: List of predicted ratings.\n",
    "    - k: Number of top recommendations to consider.\n",
    "\n",
    "    Returns:\n",
    "    - Precision@K value.\n",
    "    \"\"\"\n",
    "    # Get top K indices for predicted ratings\n",
    "    top_k_indices = np.argsort(predicted_ratings)[-k:]\n",
    "    # Count relevant items (e.g., rating >= 4) in top K\n",
    "    relevant = sum(1 for i in top_k_indices if true_ratings[i] >= 4)\n",
    "    return relevant / k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_average_precision(true_ratings, predicted_ratings):\n",
    "    \"\"\"\n",
    "    Calculates Mean Average Precision (MAP).\n",
    "\n",
    "    Parameters:\n",
    "    - true_ratings: List of true ratings.\n",
    "    - predicted_ratings: List of predicted ratings.\n",
    "\n",
    "    Returns:\n",
    "    - MAP value.\n",
    "    \"\"\"\n",
    "    # Sort indices by predicted scores in descending order\n",
    "    sorted_indices = np.argsort(predicted_ratings)[::-1]\n",
    "    relevant_count = 0\n",
    "    precision_sum = 0.0\n",
    "\n",
    "    for i, idx in enumerate(sorted_indices):\n",
    "        if true_ratings[idx] >= 4:  # Define \"relevant\" as ratings >= 4\n",
    "            relevant_count += 1\n",
    "            precision_sum += relevant_count / (i + 1)\n",
    "\n",
    "    return precision_sum / relevant_count if relevant_count > 0 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 4.0138\n",
      "Precision@5: 1.0000\n",
      "Mean Average Precision (MAP): 0.7178\n"
     ]
    }
   ],
   "source": [
    "test_true_ratings = test_df['review_rating'].values\n",
    "# RMSE\n",
    "rmse = np.sqrt(mean_squared_error(test_true_ratings, test_predictions))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "\n",
    "# Precision@K\n",
    "k = 5\n",
    "p_at_k = precision_at_k(test_true_ratings, test_predictions, k)\n",
    "print(f\"Precision@{k}: {p_at_k:.4f}\")\n",
    "\n",
    "# MAP\n",
    "map_score = mean_average_precision(test_true_ratings, test_predictions)\n",
    "print(f\"Mean Average Precision (MAP): {map_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 3.9378633218042363\n"
     ]
    }
   ],
   "source": [
    "# Predict ratings for the training set\n",
    "predicted_ratings = []\n",
    "for _, row in train_ddf.iterrows():\n",
    "    user_idx = row['user_idx']\n",
    "    business_idx = row['business_idx']\n",
    "    \n",
    "    # Predict rating using SVD matrices\n",
    "    predicted_rating = np.dot(np.dot(U[user_idx], sigma), Vt[:, business_idx])\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Compute RMSE\n",
    "rmse_train = np.sqrt(mean_squared_error(train_ddf['review_rating'], predicted_ratings))\n",
    "print(f\"Train RMSE: {rmse_train}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.17",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
